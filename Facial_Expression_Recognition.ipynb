{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt37pBC_kJdK"
      },
      "source": [
        "**Facial Expression Recognition**\n",
        "\n",
        "Classify facial expressions (e.g., happy vs. neutral) from imbalanced face image datasets.\n",
        "\n",
        "Apply augmentation (flip, brightness), preprocess with edge enhancement, extract low-level and deep features (VGG16), perform serial fusion and PCA, and classify with Linear SVM.\n",
        "\n",
        "Report accuracy, precision, recall, F1-score, and confusion matrix with 10-fold cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pu0XuFjLzyJ"
      },
      "source": [
        "# Task: Binary Imbalanced Classification Problem\n",
        "**Facial Expression Recognition**\n",
        "Steps:\n",
        "\n",
        "1. Data Preparation\n",
        "    \n",
        "  *  Data Augmentation (e.g., Flip and Rotate)\n",
        "\n",
        "  *   Data Preprocessing (e.g., image enhancement)\n",
        "\n",
        "2. Feature Engineering\n",
        "\n",
        "   *   Low-level Features (HOG, LBP, GLCM)\n",
        "\n",
        "   *   High-level / Deep Features (FC7 Layer of VGG19)\n",
        "\n",
        "3. Feature Fusion and Dimensionality Reduction\n",
        "\n",
        "    *  Feature Fusion (Serial-based) and Dimensionality Reduction (PCA)       \n",
        "\n",
        "4. Classification (Linear SVM)\n",
        "\n",
        "\n",
        "Note:\n",
        "\n",
        "Cross-validation (K-fold) where k=10, Evaluation Metrics (Accuracy,\n",
        "Precision, Recall, and F1-score). Also, show a confusion matrix.\n",
        "\n",
        "\n",
        "Tools & Technologies\n",
        "\n",
        "*  Python (OpenCV,scikit-learn, TensorFlow/Keras for VGG19).\n",
        "\n",
        "*  Libraries: NumPy,Pandas, Matplotlib/Seaborn for visualization, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0dnsaKsChp8"
      },
      "source": [
        "**Extract Req. Data from Raw data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKYQ7utXDZHG",
        "outputId": "2a9bbb7a-759d-4ba5-a0b6-8c5a5845d88c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-1-3d14dd0bee09>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  happy_neutral_df['emotion'] = happy_neutral_df['emotion'].replace({3: 1, 6: 0})\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('/content/drive/MyDrive/fer2013.csv')\n",
        "\n",
        "# Filter rows for happy (emotion=3) and neutral (emotion=6)\n",
        "happy_neutral_df = df[df['emotion'].isin([3, 6])]\n",
        "\n",
        "# Map labels: 3 -> 1 (happy), 6 -> 0 (neutral)\n",
        "happy_neutral_df['emotion'] = happy_neutral_df['emotion'].replace({3: 1, 6: 0})\n",
        "\n",
        "# Save to a new CSV file\n",
        "happy_neutral_df.to_csv('happy_neutral_fer2013.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wTUsi7GExlc",
        "outputId": "77dad917-7f0e-4970-d721-37d6680f3d4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Happy samples: 8989\n",
            "Number of Neutral samples: 6198\n",
            "Total samples: 15187\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the new CSV file\n",
        "df = pd.read_csv('happy_neutral_fer2013.csv')\n",
        "\n",
        "# Count the number of happy (emotion=1) and neutral (emotion=0) samples\n",
        "happy_count = len(df[df['emotion'] == 1])\n",
        "neutral_count = len(df[df['emotion'] == 0])\n",
        "\n",
        "# Print the counts\n",
        "print(f\"Number of Happy samples: {happy_count}\")\n",
        "print(f\"Number of Neutral samples: {neutral_count}\")\n",
        "print(f\"Total samples: {happy_count + neutral_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeYoANPQOEQO"
      },
      "source": [
        "Oversampling of Neutral Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nuQrakqQB4b",
        "outputId": "1ba6051a-38b7-4293-a0c9-e28ef061dc18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Dataset:\n",
            "Happy count: 8989\n",
            "Neutral count: 6198\n",
            "\n",
            "After Oversampling Neutral Class:\n",
            "Happy count: 8989\n",
            "Neutral count: 8900\n",
            "\n",
            "Final Balanced Dataset:\n",
            "Happy count: 8900\n",
            "Neutral count: 8900\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skimage.transform import rotate\n",
        "from skimage.exposure import adjust_gamma\n",
        "\n",
        "# ======================== Load Dataset and Inspect =============================\n",
        "# Original counts:\n",
        "# Happy samples: 8989\n",
        "# Neutral samples: 6198\n",
        "# Total: 15187\n",
        "\n",
        "df = pd.read_csv('happy_neutral_fer2013.csv')\n",
        "\n",
        "# Separate happy (majority) and neutral (minority)\n",
        "happy_df = df[df['emotion'] == 1].copy()\n",
        "neutral_df = df[df['emotion'] == 0].copy()\n",
        "\n",
        "print(\"Original Dataset:\")\n",
        "print(f\"Happy count: {len(happy_df)}\")\n",
        "print(f\"Neutral count: {len(neutral_df)}\")\n",
        "\n",
        "# ======================== Step 1: Oversample Neutral Class ======================\n",
        "# Target: Increase Neutral from 6198 to 8900 => Generate 2702 images\n",
        "\n",
        "target_neutral = 8900\n",
        "to_generate = target_neutral - len(neutral_df)\n",
        "\n",
        "# Helper functions to convert between pixel string and image\n",
        "def pixels_to_image(pixel_string):\n",
        "    return np.array(pixel_string.split(), dtype=np.float32).reshape(48, 48)\n",
        "\n",
        "def image_to_pixels(image):\n",
        "    return ' '.join(map(str, image.flatten().astype(int)))\n",
        "\n",
        "# Augmentation function\n",
        "def augment_image(image, aug_type):\n",
        "    if aug_type == 'flip':\n",
        "        return np.fliplr(image)  # Horizontal flip\n",
        "    elif aug_type == 'brighten':\n",
        "        return adjust_gamma(image, gamma=1.2)  # Slight brightness increase\n",
        "    elif aug_type == 'darken':\n",
        "        return adjust_gamma(image, gamma=0.8)  # Slight brightness decrease\n",
        "    elif aug_type == 'rotate':\n",
        "        return rotate(image, angle=10, mode='edge')  # Slight rotation\n",
        "    return image\n",
        "\n",
        "np.random.seed(42)  # For reproducibility\n",
        "augmented_rows = []\n",
        "aug_types = ['flip', 'brighten', 'darken', 'rotate']\n",
        "images_per_type = to_generate // len(aug_types)  # ~675 per type\n",
        "remaining = to_generate % len(aug_types)\n",
        "\n",
        "# Shuffle indices to avoid repetitive patterns\n",
        "neutral_indices = np.random.permutation(len(neutral_df))\n",
        "\n",
        "generated = 0\n",
        "idx = 0\n",
        "\n",
        "while generated < to_generate:\n",
        "    row = neutral_df.iloc[neutral_indices[idx % len(neutral_df)]]\n",
        "    image = pixels_to_image(row['pixels'])\n",
        "\n",
        "    aug_type_idx = min(generated // images_per_type, len(aug_types) - 1)\n",
        "    aug_type = aug_types[aug_type_idx]\n",
        "\n",
        "    aug_image = augment_image(image, aug_type)\n",
        "    aug_pixels = image_to_pixels(aug_image)\n",
        "\n",
        "    new_row = row.copy()\n",
        "    new_row['pixels'] = aug_pixels\n",
        "    augmented_rows.append(new_row)\n",
        "\n",
        "    generated += 1\n",
        "    idx += 1\n",
        "\n",
        "# Convert list of augmented rows into DataFrame\n",
        "augmented_df = pd.DataFrame(augmented_rows)\n",
        "\n",
        "# Combine original and augmented neutral data\n",
        "new_neutral_df = pd.concat([neutral_df, augmented_df], ignore_index=True)\n",
        "\n",
        "# Combine oversampled neutral with original happy (still imbalanced at this stage)\n",
        "combined_oversampled_df = pd.concat([happy_df, new_neutral_df], ignore_index=True)\n",
        "\n",
        "print(\"\\nAfter Oversampling Neutral Class:\")\n",
        "print(f\"Happy count: {len(happy_df)}\")\n",
        "print(f\"Neutral count: {len(new_neutral_df)}\")\n",
        "\n",
        "# ======================== Step 2: Downsample Happy Class =======================\n",
        "# Now downsample happy class to match neutral count (8900)\n",
        "\n",
        "# Re-separate after oversampling\n",
        "happy_df = combined_oversampled_df[combined_oversampled_df['emotion'] == 1].copy()\n",
        "neutral_df = combined_oversampled_df[combined_oversampled_df['emotion'] == 0].copy()\n",
        "\n",
        "# Downsample happy class to 8900 samples\n",
        "np.random.seed(42)\n",
        "happy_indices = np.random.choice(len(happy_df), size=8900, replace=False)\n",
        "downsampled_happy_df = happy_df.iloc[happy_indices].reset_index(drop=True)\n",
        "\n",
        "# Combine downsampled happy with oversampled neutral\n",
        "final_balanced_df = pd.concat([downsampled_happy_df, neutral_df], ignore_index=True)\n",
        "\n",
        "# Save final balanced dataset\n",
        "final_balanced_df.to_csv('happy_neutral_balanced.csv', index=False)\n",
        "\n",
        "# Print final balanced counts\n",
        "print(\"\\nFinal Balanced Dataset:\")\n",
        "print(f\"Happy count: {len(final_balanced_df[final_balanced_df['emotion'] == 1])}\")\n",
        "print(f\"Neutral count: {len(final_balanced_df[final_balanced_df['emotion'] == 0])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hmj5F3DhY3XD",
        "outputId": "44d1be38-f442-44e3-abcc-3e83c62eda8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing complete. Preprocessed data saved to 'happy_neutral_preprocessed.csv'.\n",
            "Total samples: 17800\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('happy_neutral_balanced.csv')\n",
        "\n",
        "# Function to convert pixel string to 48x48 image\n",
        "def pixels_to_image(pixel_string):\n",
        "    # Convert pixel string to array, handle out-of-range values\n",
        "    pixels = np.array(pixel_string.split(), dtype=np.float32)\n",
        "    # Clamp values to [0, 255] to prevent overflow\n",
        "    pixels = np.clip(pixels, 0, 255)\n",
        "    return pixels.reshape(48, 48).astype(np.uint8)\n",
        "\n",
        "# Function to convert image back to pixel string\n",
        "def image_to_pixels(image):\n",
        "    return ' '.join(map(str, image.flatten().astype(int)))\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_image(image):\n",
        "    # Histogram Equalization for contrast enhancement\n",
        "    image = cv2.equalizeHist(image)\n",
        "    # Normalization to [0,1]\n",
        "    image = image / 255.0\n",
        "    # Scale back to [0,255] and clamp to prevent overflow\n",
        "    image = np.clip(image * 255, 0, 255).astype(np.uint8)\n",
        "    return image\n",
        "\n",
        "# Apply preprocessing to all images\n",
        "preprocessed_pixels = []\n",
        "for pixel_string in df['pixels']:\n",
        "    # Convert pixel string to image\n",
        "    image = pixels_to_image(pixel_string)\n",
        "    # Apply preprocessing\n",
        "    image = preprocess_image(image)\n",
        "    # Convert back to pixel string\n",
        "    pixel_string = image_to_pixels(image)\n",
        "    preprocessed_pixels.append(pixel_string)\n",
        "\n",
        "# Update the DataFrame with preprocessed pixels\n",
        "df['pixels'] = preprocessed_pixels\n",
        "\n",
        "# Save to a new CSV file\n",
        "df.to_csv('happy_neutral_preprocessed.csv', index=False)\n",
        "\n",
        "# Print confirmation\n",
        "print(\"Preprocessing complete. Preprocessed data saved to 'happy_neutral_preprocessed.csv'.\")\n",
        "print(f\"Total samples: {len(df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnKQj7TloltV",
        "outputId": "1095fc9f-e51e-45d6-a207-7190a3b86b75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS-EF9vyaGDT",
        "outputId": "75c4022c-9817-4743-e760-aa19026e5587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature extraction complete. Features saved to 'happy_neutral_features.csv'.\n",
            "Total samples: 17800\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skimage.feature import hog, local_binary_pattern, graycomatrix, graycoprops\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "import cv2\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('happy_neutral_preprocessed.csv')\n",
        "\n",
        "# Function to convert pixel string to 48x48 image\n",
        "def pixels_to_image(pixel_string):\n",
        "    pixels = np.array(pixel_string.split(), dtype=np.uint8)\n",
        "    return pixels.reshape(48, 48)\n",
        "\n",
        "# Function to resize image for VGG19\n",
        "def resize_for_vgg(image):\n",
        "    return cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "# Extract Low-level Features\n",
        "hog_features = []\n",
        "lbp_features = []\n",
        "glcm_features = []\n",
        "\n",
        "for pixel_string in df['pixels']:\n",
        "    # Convert to image\n",
        "    image = pixels_to_image(pixel_string)\n",
        "\n",
        "    # HOG Features\n",
        "    hog_feature, _ = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
        "    hog_features.append(hog_feature)\n",
        "\n",
        "    # LBP Features\n",
        "    lbp = local_binary_pattern(image, P=8, R=1, method='uniform')\n",
        "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 10), range=(0, 9))\n",
        "    lbp_features.append(hist / hist.sum())  # Normalize\n",
        "\n",
        "    # GLCM Features\n",
        "    glcm = graycomatrix(image, distances=[5], angles=[0], levels=256, symmetric=True, normed=True)\n",
        "    glcm_props = [graycoprops(glcm, prop).ravel()[0] for prop in ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']]\n",
        "    glcm_features.append(glcm_props)\n",
        "\n",
        "# Convert feature lists to arrays\n",
        "hog_features = np.array(hog_features)\n",
        "lbp_features = np.array(lbp_features)\n",
        "glcm_features = np.array(glcm_features)\n",
        "\n",
        "# Extract High-level Features (VGG19 FC7 Layer)\n",
        "base_model = VGG19(weights='imagenet', include_top=True)\n",
        "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)  # FC7 layer\n",
        "\n",
        "vgg_features = []\n",
        "for pixel_string in df['pixels']:\n",
        "    image = pixels_to_image(pixel_string)\n",
        "    image = resize_for_vgg(image)\n",
        "    image = np.stack([image] * 3, axis=-1)  # Convert grayscale to RGB by stacking\n",
        "    image = preprocess_input(image * 255)  # VGG19 expects [0,255] range\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    feature = model.predict(image, verbose=0)\n",
        "    vgg_features.append(feature.flatten())\n",
        "\n",
        "vgg_features = np.array(vgg_features)\n",
        "\n",
        "# Add features to DataFrame\n",
        "df['hog_features'] = [','.join(map(str, f)) for f in hog_features]\n",
        "df['lbp_features'] = [','.join(map(str, f)) for f in lbp_features]\n",
        "df['glcm_features'] = [','.join(map(str, f)) for f in glcm_features]\n",
        "df['vgg19_features'] = [','.join(map(str, f)) for f in vgg_features]\n",
        "\n",
        "# Save to a new CSV file\n",
        "df.to_csv('happy_neutral_features.csv', index=False)\n",
        "\n",
        "# Print confirmation\n",
        "print(\"Feature extraction complete. Features saved to 'happy_neutral_features.csv'.\")\n",
        "print(f\"Total samples: {len(df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faJdUIq0lwji",
        "outputId": "a983a72a-7a72-4ef8-883f-a48c0a0ee4af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: 'vgg_features' column not found. Proceeding without VGG features.\n",
            "Original feature shape: (17800, 914)\n",
            "Reduced feature shape after PCA: (17800, 408)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Step 1: Load the feature CSV\n",
        "df = pd.read_csv('happy_neutral_features.csv')\n",
        "\n",
        "# Step 2: Convert string features into numerical arrays\n",
        "def parse_feature_column(column):\n",
        "    return np.array([np.fromstring(f, sep=',') for f in df[column]])\n",
        "\n",
        "# Step 3: Parse available features\n",
        "hog = parse_feature_column('hog_features')\n",
        "lbp = parse_feature_column('lbp_features')\n",
        "glcm = parse_feature_column('glcm_features')\n",
        "\n",
        "# Step 4: Check if VGG features exist\n",
        "if 'vgg_features' in df.columns:\n",
        "    vgg = parse_feature_column('vgg_features')\n",
        "    fused_features = np.hstack([hog, lbp, glcm, vgg])\n",
        "    print(\"VGG features included in fusion.\")\n",
        "else:\n",
        "    fused_features = np.hstack([hog, lbp, glcm])\n",
        "    print(\"Warning: 'vgg_features' column not found. Proceeding without VGG features.\")\n",
        "\n",
        "# Step 5: Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "fused_scaled = scaler.fit_transform(fused_features)\n",
        "\n",
        "# Step 6: PCA Dimensionality Reduction\n",
        "pca = PCA(n_components=0.99, random_state=42)  # retain 99% variance\n",
        "fused_pca = pca.fit_transform(fused_scaled)\n",
        "\n",
        "# Step 7: Output\n",
        "print(\"Original feature shape:\", fused_features.shape)\n",
        "print(\"Reduced feature shape after PCA:\", fused_pca.shape)\n",
        "\n",
        "# Optional: Save for classification step\n",
        "np.save('fused_features_pca.npy', fused_pca)\n",
        "np.save('labels.npy', df['emotion'].values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBgrKP_8lyTg",
        "outputId": "4faca981-b763-4ad8-db14-105731ce7a6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing 10-Fold Cross-Validation...\n",
            "Class-wise Metrics:\n",
            "Neutral - Precision: 0.80, Recall: 0.79, F1: 0.80\n",
            "Happy   - Precision: 0.80, Recall: 0.81, F1: 0.80\n",
            "\n",
            "Overall Accuracy: 0.80\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "# Step 1: Load features and labels\n",
        "X = np.load('fused_features_pca.npy')  # shape: (samples, reduced_features)\n",
        "y = np.load('labels.npy')              # shape: (samples,)\n",
        "\n",
        "# Step 2: Define 10-fold stratified cross-validation\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Step 3: Initialize Linear SVM\n",
        "svm = LinearSVC(max_iter=10000, random_state=42)\n",
        "\n",
        "# Step 4: Cross-validate and predict\n",
        "print(\"Performing 10-Fold Cross-Validation...\")\n",
        "y_pred = cross_val_predict(svm, X, y, cv=cv)\n",
        "\n",
        "# Step 5 (Alternative): Get numerical values of metrics\n",
        "precision, recall, f1, support = precision_recall_fscore_support(y, y_pred, average=None, labels=[0, 1])\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "\n",
        "print(\"Class-wise Metrics:\")\n",
        "print(f\"Neutral - Precision: {precision[0]:.2f}, Recall: {recall[0]:.2f}, F1: {f1[0]:.2f}\")\n",
        "print(f\"Happy   - Precision: {precision[1]:.2f}, Recall: {recall[1]:.2f}, F1: {f1[1]:.2f}\")\n",
        "print(f\"\\nOverall Accuracy: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwyV7FYFOePC",
        "outputId": "ecb30391-e94a-4125-af5e-79af0baf9c9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as 'linear_svm_model.joblib'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from joblib import dump  # or use pickle if you prefer\n",
        "\n",
        "# Load fused PCA features and labels\n",
        "X = np.load('fused_features_pca.npy')\n",
        "y = np.load('labels.npy')\n",
        "\n",
        "# Initialize and train Linear SVM on full data\n",
        "svm = LinearSVC(max_iter=10000, random_state=42)\n",
        "svm.fit(X, y)\n",
        "\n",
        "# Save the model\n",
        "dump(svm, 'linear_svm_model.joblib')\n",
        "dump(scaler, 'scaler.joblib')\n",
        "dump(pca, 'pca.joblib')\n",
        "\n",
        "print(\"Model saved as 'linear_svm_model.joblib'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict_emotion.py\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import hog, local_binary_pattern, graycomatrix, graycoprops\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from joblib import load\n",
        "\n",
        "# Load the trained model, scaler, and PCA\n",
        "try:\n",
        "    svm = load('linear_svm_model.joblib')\n",
        "    scaler = load('scaler.joblib')\n",
        "    pca = load('pca.joblib')\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: {e}. Ensure 'linear_svm_model.joblib', 'scaler.joblib', and 'pca.joblib' are in the directory.\")\n",
        "    exit()\n",
        "\n",
        "# Preprocess the image (same as training)\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Could not load image from {image_path}\")\n",
        "    image = cv2.resize(image, (48, 48), interpolation=cv2.INTER_AREA)\n",
        "    image = cv2.equalizeHist(image)\n",
        "    return image\n",
        "\n",
        "# Feature extraction (adjusted to match training)\n",
        "def extract_features(image):\n",
        "    # HOG (adjust parameters to match ~324 features)\n",
        "    hog_f, _ = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
        "    print(f\"HOG shape: {hog_f.shape}\")  # Debug\n",
        "    # If HOG is still 900, try reducing cell size or block overlap\n",
        "    if hog_f.shape[0] != 324:  # Expected training HOG size\n",
        "        hog_f, _ = hog(image, orientations=9, pixels_per_cell=(16, 16), cells_per_block=(2, 2), visualize=True)\n",
        "        print(f\"Adjusted HOG shape: {hog_f.shape}\")  # Debug\n",
        "    # LBP\n",
        "    lbp = local_binary_pattern(image, P=8, R=1, method='uniform')\n",
        "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 10), range=(0, 9))\n",
        "    lbp_f = hist / hist.sum()\n",
        "    print(f\"LBP shape: {lbp_f.shape}\")  # Debug\n",
        "    # GLCM\n",
        "    glcm = graycomatrix(image, distances=[5], angles=[0], levels=256, symmetric=True, normed=True)\n",
        "    glcm_f = [graycoprops(glcm, prop).ravel()[0] for prop in ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']]\n",
        "    glcm_f = np.array(glcm_f)\n",
        "    print(f\"GLCM shape: {glcm_f.shape}\")  # Debug\n",
        "    # VGG16 FC1\n",
        "    base_model = VGG16(weights='imagenet', include_top=True)\n",
        "    model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)  # FC1: 4096\n",
        "    img = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "    img = np.stack([img] * 3, axis=-1)  # Convert to RGB\n",
        "    img = preprocess_input(img * 255)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    vgg_f = model.predict(img, verbose=0).flatten()\n",
        "    print(f\"VGG16 shape: {vgg_f.shape}\")  # Debug\n",
        "    # Fuse features\n",
        "    fused = np.hstack([hog_f, lbp_f, glcm_f, vgg_f])\n",
        "    print(f\"Fused shape before adjustment: {fused.shape}\")  # Debug\n",
        "    # Adjust to match training's 914 features\n",
        "    expected_total = 914\n",
        "    hog_len, lbp_len, glcm_len = len(hog_f), len(lbp_f), len(glcm_f)\n",
        "    vgg_len = expected_total - (hog_len + lbp_len + glcm_len)\n",
        "    if vgg_len <= 0 or vgg_len > len(vgg_f):\n",
        "        raise ValueError(f\"Cannot adjust VGG16 features to fit {expected_total}. Got VGG length {len(vgg_f)}, need {vgg_len}. Check HOG parameters.\")\n",
        "    fused = np.hstack([hog_f, lbp_f, glcm_f, vgg_f[:vgg_len]])\n",
        "    print(f\"Fused shape after adjustment: {fused.shape}\")  # Debug\n",
        "    # Apply scaler and PCA\n",
        "    if fused.shape[0] != expected_total:\n",
        "        raise ValueError(f\"Expected {expected_total} features, got {fused.shape[0]}. Adjust feature extraction.\")\n",
        "    fused_scaled = scaler.transform(fused.reshape(1, -1))\n",
        "    fused_pca = pca.transform(fused_scaled)\n",
        "    print(f\"PCA shape: {fused_pca.shape}\")  # Debug\n",
        "    return fused_pca\n",
        "\n",
        "# Predict\n",
        "def predict_emotion(image_path):\n",
        "    image = preprocess_image(image_path)\n",
        "    features = extract_features(image)\n",
        "    prediction = svm.predict(features)\n",
        "    return \"Happy\" if prediction[0] == 1 else \"Neutral\"\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    image_path = \"/content/gettyimages-1465122813-612x612.jpg\"  # Replace with your image path\n",
        "    try:\n",
        "        result = predict_emotion(image_path)\n",
        "        print(f\"Prediction: {result}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCF5ozQG8GP2",
        "outputId": "b96d30a7-101e-4883-c026-f0126208160f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HOG shape: (900,)\n",
            "Adjusted HOG shape: (144,)\n",
            "LBP shape: (9,)\n",
            "GLCM shape: (5,)\n",
            "VGG16 shape: (4096,)\n",
            "Fused shape before adjustment: (4254,)\n",
            "Fused shape after adjustment: (914,)\n",
            "PCA shape: (1, 408)\n",
            "Prediction: Happy\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}